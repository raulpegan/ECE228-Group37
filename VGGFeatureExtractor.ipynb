{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata_path = './skin-cancer-mnist-ham10000/HAM10000_metadata.csv'\n",
    "# metadat = pd.read_csv(metadata_path)\n",
    "# num_samples = len(metadat)\n",
    "# metadat = metadat.sample(frac=1,random_state=12).reset_index(drop=True) #shuffling data\n",
    "\n",
    "# #metadat = metadat['image_id'].add('.jpg')\n",
    "# metadat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "\n",
    "img_width, img_height = 224, 224\n",
    "train_data_dir = \"./train\"\n",
    "val_data_dir = \"./val\"\n",
    "batch_size = 1\n",
    "\n",
    "vgg = VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the train and test generators with data Augumentation \n",
    "train_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = True,\n",
    "zoom_range = 0.2,\n",
    "shear_range=0.2\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = True,\n",
    "zoom_range = 0.2,\n",
    "shear_range=0.2\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "train_data_dir,\n",
    "target_size = (img_height, img_width),\n",
    "batch_size = batch_size, \n",
    "class_mode = \"categorical\", \n",
    "shuffle = True, \n",
    "seed = 12\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "val_data_dir,\n",
    "target_size = (img_height, img_width),\n",
    "batch_size = batch_size, \n",
    "class_mode = \"categorical\", \n",
    "shuffle = True, \n",
    "seed = 12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = []\n",
    "train_lbl  = []\n",
    "\n",
    "val_feat   = []\n",
    "val_lbl    = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_generator)):\n",
    "    nxt_data = train_generator.next()\n",
    "    feature = vgg.predict(nxt_data[0])\n",
    "    train_feat.append(feature.flatten())\n",
    "    train_lbl.append(nxt_data[1])\n",
    "# for i in range(len(train_generator)):\n",
    "#     feature = vgg.predict(train_generator[i][0])\n",
    "#     train_feat.append(feature.flatten())\n",
    "#     train_lbl.append(train_generator[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(val_generator)):\n",
    "    nxt_data = val_generator.next()\n",
    "    feature = vgg.predict(nxt_data[0])\n",
    "    val_feat.append(feature.flatten())\n",
    "    val_lbl.append(nxt_data[1])\n",
    "# for i in range(len(val_generator)):\n",
    "#     feature = vgg.predict(val_generator[i][0])\n",
    "#     val_feat.append(feature.flatten())\n",
    "#     val_lbl.append(val_generator[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "#     # Compute confusion matrix\n",
    "#     cm = confusion_matrix(y_true, y_pred)\n",
    "#     # Only use the labels that appear in the data\n",
    "#     classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "class_names = np.array(['akiec','bcc','bkl','df','mel','nv','vasc'])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# # Plot non-normalized confusion matrix\n",
    "# plot_confusion_matrix(cm, classes=class_names,\n",
    "#                       title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KMEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "kmeans = KMeans(n_clusters=7, random_state=0).fit(train_feat)\n",
    "\n",
    "\n",
    "y_tr = np.argmax(train_lbl,axis=2)\n",
    "yhat_tr = kmeans.predict(train_feat)\n",
    "count = np.zeros((7,7))\n",
    "for i in range(len(y_tr)):\n",
    "    count[int(y_tr[i])][yhat_tr[i]] += 1\n",
    "\n",
    "mapping = np.argmax(count,axis=0) #index is the cluster label, value is the 'true' label\n",
    "\n",
    "#since labels are repeated, tiebreaker was the next highest prediction value\n",
    "count1 = np.exp(count) / np.sum(np.exp(count), axis=0)\n",
    "np.set_printoptions(precision=2)\n",
    "#manually picked after looking at training data predictions\n",
    "mapping1 = np.array([6, 5, 1, 4, 0, 2, 3])\n",
    "\n",
    "kmeans_val_pred = kmeans.predict(val_feat)\n",
    "\n",
    "y_val = np.argmax(val_lbl,axis=2)\n",
    "\n",
    "acc = 0\n",
    "for i in range(len(kmeans_val_pred)):\n",
    "    if y_val[i] == mapping[kmeans_val_pred[i]]:\n",
    "        acc += 1/len(kmeans_val_pred)\n",
    "print('accuracy = ' + str(acc))\n",
    "\n",
    "kmeans_cm = confusion_matrix(y_val,kmeans_val_pred)\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(kmeans_cm, classes=class_names, normalize=True,\n",
    "                      title='K means confusion matrix')\n",
    "plt.savefig('kmeans_conf_mat.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "knn = KNeighborsClassifier(n_neighbors=5)  \n",
    "knn.fit(train_feat, y_tr)  \n",
    "\n",
    "yhat = knn.predict(val_feat)\n",
    "\n",
    "\n",
    "knn_cm = confusion_matrix(y_val, yhat)\n",
    "print(knn_cm)\n",
    "knn_acc = np.sum(np.diag(knn_cm))/np.sum(knn_cm)\n",
    "print('accuracy = ' + str(knn_acc))\n",
    "print(classification_report(y_val, yhat)) \n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(knn_cm, classes=class_names, normalize=True,\n",
    "                      title='KNN confusion matrix')\n",
    "plt.savefig('10nn_conf_mat.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.utils.class_weight import compute_class_weight,compute_sample_weight\n",
    "\n",
    "y_tr = np.argmax(train_lbl,axis=2)\n",
    "\n",
    "class_weights = compute_class_weight('balanced', np.unique(y_tr[:,0]), y_tr[:,0])\n",
    "svc = SVC(class_weight='balanced')\n",
    "\n",
    "svc.fit(train_feat,y_tr,sample_weight=compute_sample_weight(class_weight='balanced', y=y_tr))\n",
    "\n",
    "yhat = svc.predict(val_feat)\n",
    "\n",
    "svc_cm = confusion_matrix(y_val, yhat)\n",
    "print(svc_cm)\n",
    "svc_acc = np.sum(np.diag(svc_cm))/np.sum(svc_cm)\n",
    "print(classification_report(y_val, yhat)) \n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(svc_cm, classes=class_names, normalize=True,\n",
    "                      title='KNN confusion matrix')\n",
    "plt.savefig('svc_conf_mat.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
